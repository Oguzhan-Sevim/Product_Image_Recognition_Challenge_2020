{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os # this library provides easy access to the local file directories\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2 # opencv library for image processing purposes\n",
    "\n",
    "from sklearn import model_selection # for train-test split\n",
    "\n",
    "# Import the image augmentation library.\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Import the VGG-16 model:\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Import required Keras classes\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify some model parameters:\n",
    "\n",
    "image_size = 128  # Each image in the dataset will be resized to (image_size x image_size x 3)\n",
    "test_size  = 0.50 # Choose the ratio of test set\n",
    "valid_portion = 0.20\n",
    "\n",
    "data_augmentation = True # Choose whether to apply augmentation or not\n",
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_function(X, y):\n",
    "    # Save the previous versions of data. \n",
    "    X_temp = X\n",
    "    y_temp = y\n",
    "    \n",
    "    # First augmentation: Apply horizontal mirroring on each image.\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(1.0)\n",
    "    ])\n",
    "    X = np.concatenate((X, seq(images = X_temp)), axis=0)\n",
    "    y = np.concatenate((y, y_temp), axis=0)\n",
    "        \n",
    "    # Second augmentation: Add Gaussian noise on each image. \n",
    "    # The noise on each pixel and channels is independently sampled from normal dist. of N(0, 0.25*255).\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.25*255), per_channel=True)\n",
    "    ])\n",
    "    X = np.concatenate((X, seq(images = X_temp)), axis=0)\n",
    "    y = np.concatenate((y, y_temp), axis=0)\n",
    "      \n",
    "    # Third augmentation: Random cropping. We randomly pick a window from each image.\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(px=(0, 32)) # crop images from each side by 0 to 32px (randomly chosen)\n",
    "    ])\n",
    "    X = np.concatenate((X, seq(images = X_temp)), axis=0)\n",
    "    y = np.concatenate((y, y_temp), axis=0)\n",
    "        \n",
    "    # Fourth augmentation: Rotate (between -45 to 45 degrees) and shear (from -16 to 16 degrees). \n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Affine(rotate=(-45, 45), shear=(-16, 16))\n",
    "    ])\n",
    "    X = np.concatenate((X, seq(images = X_temp)), axis=0)\n",
    "    y = np.concatenate((y, y_temp), axis=0)\n",
    "    \n",
    "    # Fifth augmentation: Play with the colors.\n",
    "    # First, convert the images to HSV and add random values (-50 to 50) to H-S channels of the image. Then turn back to RGB.\n",
    "    # Second, change brightness by changing V (value) of HSV.\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.AddToHueAndSaturation((-50, 50), per_channel=True),\n",
    "        iaa.WithBrightnessChannels(iaa.Add((-50, 50)))\n",
    "    ])\n",
    "    X = np.concatenate((X, seq(images = X_temp)), axis=0)\n",
    "    y = np.concatenate((y, y_temp), axis=0)\n",
    "    \n",
    "    del X_temp, y_temp, seq\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS BLOCK ONLY ONCE. IT WILL SAVE 2 NUMPY ARRAYS ON THE DIRECTORY, SO THAT YOU CAN LOAD THEM THEREAFTER. \n",
    "\n",
    "# folder should be the directory of the SKU_Recognition_Dataset folder. Change it accordingly. \n",
    "folder = 'C:/Users/Mecha/Desktop/Graduate_Courses/EE58J_DataMining/HW1/SKU_Recognition_Dataset'\n",
    "\n",
    "# We will use 2 for loops in order to go through all confectionery (or icecream) SKUs (class labels) and images respectively.\n",
    "# For each image, we will first read, then normalize its size, and stack them in X-y arrays to perform augmentation\n",
    "\n",
    "y = [] # We will collect the labels of dataset in this list\n",
    "X = np.empty((0, image_size, image_size, 3), dtype = np.uint8) # Each image will be stored in this 4D array\n",
    "cls = 0\n",
    "classNameDic = {}\n",
    "classList = []\n",
    "\n",
    "#category_name = 'icecream'\n",
    "category_name = 'confectionery'\n",
    "\n",
    "folder = folder+'/'+category_name   # folder is the directory of the given category folder\n",
    "\n",
    "for class_name in os.listdir(folder): # .listdir() method willl return a list that contains all the folder names\n",
    "    print(cls)\n",
    "    \n",
    "    classNameDic.update({cls: class_name})\n",
    "    classList.append(class_name)\n",
    "    class_folder = folder+'/'+class_name  # class_folder is the directory of a SKU folder that contains ~100 jpeg images\n",
    "    for image_name in os.listdir(class_folder):\n",
    "            \n",
    "        # Create the direct path to a single image:\n",
    "        final_directory = class_folder+'/'+image_name\n",
    "        \n",
    "        # Read the image as a (x,y,3) numpy array:\n",
    "        image = cv2.imread(final_directory)\n",
    "            \n",
    "        # Resize it to (image_size,image_size,3) array:\n",
    "        image = cv2.resize(image, (image_size,image_size))\n",
    "        \n",
    "        # Convert the BGR to HSV format (optional):\n",
    "        # image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Store data in 4D numpy array\n",
    "        X = np.concatenate((X, np.expand_dims(image, axis=0)), axis=0)\n",
    "        y.append(cls)\n",
    "        \n",
    "    cls += 1\n",
    "    \n",
    "y = np.asarray(y)\n",
    "\n",
    "# Save the data to local folder. You only run this block once. You can load the data once you save it.\n",
    "np.save('X_icecream.npy', X)\n",
    "np.save('y_icecream.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS BLOCK TO SEE THE EXAMPLES OF AUGMENTED IMAGES. THIS BLOCK DOES NOT HAVE ANY OTHER FUNCTION.\n",
    "\n",
    "final_directory = \"C:/Users/Mecha/Desktop/Graduate_Courses/EE58J_DataMining/HW1/SKU_Recognition_Dataset/icecream/sku.415/crop_1783040.jpg\"\n",
    "\n",
    "image_test = cv2.imread(final_directory)\n",
    "image_test = cv2.resize(image_test, (image_size,image_size))\n",
    "image_test = np.expand_dims(image_test, axis=0)\n",
    "\n",
    "X = np.empty((0, image_size, image_size, 3), dtype = np.uint8) # Each image will be stored in this 4D array\n",
    "X = np.concatenate((X, image_test), axis=0)\n",
    "\n",
    "y = np.array([1])\n",
    "\n",
    "# Apply data augmentation\n",
    "\n",
    "X_aug, y_aug = augmentation_function(X, y)\n",
    "\n",
    "print(X_aug.shape)\n",
    "    \n",
    "cv2.imshow(\"test\", X_aug[5,:,:,:])\n",
    "#cv2.imshow(\"test\", image_test[0,:,:,:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('C:/Users/Mecha/Desktop/Graduate_Courses/EE58J_DataMining/HW4/5.jpg', X_aug[5,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from local driver.\n",
    "X = np.load('X_confec.npy')\n",
    "y = np.load('y_confec.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 128, 128, 3) (1032,)\n",
      "(6192, 128, 128, 3) (6192,)\n",
      "(4953, 128, 128, 3) (4953,)\n",
      "(1239, 128, 128, 3) (1239,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into test and training data. By choosing stratify=y, each class will be split approximately by 20-80 ratio. \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y,\n",
    "                                                random_state = 2,\n",
    "                                                stratify=y,\n",
    "                                                test_size=test_size)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Apply data augmentation on the training set:\n",
    "if data_augmentation == 1:\n",
    "    X_train, y_train = augmentation_function(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Split the traning data into training and validation data. By choosing stratify=y, each class will be split with equal ratio. \n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X_train, y_train,\n",
    "                                                random_state = 3,\n",
    "                                                stratify=y_train,\n",
    "                                                test_size=valid_portion)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 model pretrained on ImageNet dataset. include_top=False discards the last fully connected layer.\n",
    "# So, we can add any fully connected layer(s) at the end.\n",
    "VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape = (image_size, image_size, 3) )\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "out = VGG16_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "# let's add two fully-connected layers:\n",
    "#out = Dense(512, activation='relu')(out)\n",
    "#out = Dropout(0.25)(out)\n",
    "out = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(out)\n",
    "out = Dropout(0.20)(out)\n",
    "# and a logistic layer (output layer). Number of units will be equal to number of classes.\n",
    "predictions = Dense(np.unique(y_train).size, activation='softmax')(out)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=VGG16_model.input, outputs=predictions)\n",
    "\n",
    "# Train only the top layers. i.e. freeze all convolutional layers\n",
    "#for layer in VGG16_model.layers:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[:17]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4953 samples, validate on 1239 samples\n",
      "Epoch 1/30\n",
      "4953/4953 [==============================] - 1559s 315ms/sample - loss: 6.0169 - accuracy: 0.2863 - val_loss: 3.0310 - val_accuracy: 0.5246\n",
      "Epoch 2/30\n",
      "4953/4953 [==============================] - 1555s 314ms/sample - loss: 2.7702 - accuracy: 0.5389 - val_loss: 2.1935 - val_accuracy: 0.6651\n",
      "Epoch 3/30\n",
      "4953/4953 [==============================] - 1555s 314ms/sample - loss: 2.0375 - accuracy: 0.6638 - val_loss: 1.7530 - val_accuracy: 0.7264\n",
      "Epoch 4/30\n",
      "4953/4953 [==============================] - 1543s 312ms/sample - loss: 1.5925 - accuracy: 0.7444 - val_loss: 1.4025 - val_accuracy: 0.8241\n",
      "Epoch 5/30\n",
      "4953/4953 [==============================] - 1542s 311ms/sample - loss: 1.2295 - accuracy: 0.8157 - val_loss: 1.1963 - val_accuracy: 0.8216\n",
      "Epoch 6/30\n",
      "4953/4953 [==============================] - 1537s 310ms/sample - loss: 0.9561 - accuracy: 0.8801 - val_loss: 0.9794 - val_accuracy: 0.8660\n",
      "Epoch 7/30\n",
      "4953/4953 [==============================] - 1546s 312ms/sample - loss: 0.7585 - accuracy: 0.9122 - val_loss: 0.8393 - val_accuracy: 0.8910\n",
      "Epoch 8/30\n",
      "4953/4953 [==============================] - 1548s 313ms/sample - loss: 0.6883 - accuracy: 0.9200 - val_loss: 0.8593 - val_accuracy: 0.8927\n",
      "Epoch 9/30\n",
      "4953/4953 [==============================] - 1543s 312ms/sample - loss: 0.6235 - accuracy: 0.9301 - val_loss: 0.6965 - val_accuracy: 0.9031\n",
      "Epoch 10/30\n",
      "4953/4953 [==============================] - 1537s 310ms/sample - loss: 0.4859 - accuracy: 0.9600 - val_loss: 0.6844 - val_accuracy: 0.9088\n",
      "Epoch 11/30\n",
      "4953/4953 [==============================] - 1539s 311ms/sample - loss: 0.4424 - accuracy: 0.9626 - val_loss: 0.6851 - val_accuracy: 0.9007\n",
      "Epoch 12/30\n",
      "4953/4953 [==============================] - 1545s 312ms/sample - loss: 0.3641 - accuracy: 0.9770 - val_loss: 0.5683 - val_accuracy: 0.9193\n",
      "Epoch 13/30\n",
      "4953/4953 [==============================] - 1541s 311ms/sample - loss: 0.3266 - accuracy: 0.9828 - val_loss: 0.6092 - val_accuracy: 0.9056\n",
      "Epoch 14/30\n",
      "4953/4953 [==============================] - 1544s 312ms/sample - loss: 0.3016 - accuracy: 0.9810 - val_loss: 0.5960 - val_accuracy: 0.9144\n",
      "Epoch 15/30\n",
      "4953/4953 [==============================] - 1538s 311ms/sample - loss: 0.2699 - accuracy: 0.9841 - val_loss: 0.5404 - val_accuracy: 0.9193\n",
      "Epoch 16/30\n",
      "4953/4953 [==============================] - 1541s 311ms/sample - loss: 0.2402 - accuracy: 0.9905 - val_loss: 0.4720 - val_accuracy: 0.9330\n",
      "Epoch 17/30\n",
      "4953/4953 [==============================] - 1542s 311ms/sample - loss: 0.2216 - accuracy: 0.9897 - val_loss: 0.5133 - val_accuracy: 0.9193\n",
      "Epoch 18/30\n",
      "4953/4953 [==============================] - 1543s 312ms/sample - loss: 0.2292 - accuracy: 0.9849 - val_loss: 0.5335 - val_accuracy: 0.9096\n",
      "Epoch 19/30\n",
      "4953/4953 [==============================] - 1543s 312ms/sample - loss: 0.2231 - accuracy: 0.9834 - val_loss: 0.5101 - val_accuracy: 0.9266\n",
      "Epoch 20/30\n",
      "4953/4953 [==============================] - 1543s 312ms/sample - loss: 0.2079 - accuracy: 0.9836 - val_loss: 0.5484 - val_accuracy: 0.9096\n",
      "1033/1 - 252s\n",
      "Test set accuracy is 81.51016456921587\n",
      "4953/1 - 1207s\n",
      "Training set accuracy is 99.15202907328892\n"
     ]
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "callback = EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, callbacks=[callback], validation_data = (X_valid, y_valid))\n",
    "\n",
    "# Make predictions on test set\n",
    "y_prediction = model.predict(x=X_test.astype(\"float16\"), batch_size=batch_size, verbose=2)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "\n",
    "# Find the accuracy score and print it:\n",
    "score = 100 * sum(y_prediction == y_test) / y_prediction.shape[0]\n",
    "print(\"Test set accuracy is {}\".format(score))\n",
    "\n",
    "# Find training set accuracy:\n",
    "y_train_prediction = model.predict(x=X_train.astype(\"float16\"), batch_size=batch_size, verbose=2)\n",
    "y_train_prediction = np.argmax(y_train_prediction, axis=1)\n",
    "\n",
    "# Find the accuracy score and print it:\n",
    "score = 100 * sum(y_train_prediction == y_train) / y_train_prediction.shape[0]\n",
    "print(\"Training set accuracy is {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, VGG16_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
